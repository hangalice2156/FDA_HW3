{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3-1 S&P 500 Stock Prediction\n",
    "\n",
    "## About Data\n",
    "\n",
    "Data set: S&P500 stock price for specific dates, you may refer to test.csv and train.csv for detailed date.\n",
    "\n",
    "There are 6 lables: Date, Open Price(開盤價), Close Price(收盤價), High Price(當日最高價), Low Price(當日最低價), Volume(成交量)\n",
    "\n",
    "The result we want is to predice stock movement, to determine whether is go higher or lower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model, metrics, model_selection, neural_network, svm\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 2262 entries, 0 to 2261\nData columns (total 5 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   Open Price   2262 non-null   float64\n 1   Close Price  2262 non-null   float64\n 2   High Price   2262 non-null   float64\n 3   Low Price    2262 non-null   float64\n 4   Volume       2262 non-null   int64  \ndtypes: float64(4), int64(1)\nmemory usage: 88.5 KB\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Open Price  Close Price  High Price  Low Price      Volume\n0      902.99       931.80      934.73     899.35  4048270080\n1      929.17       927.45      936.63     919.53  5413910016\n2      931.17       934.70      943.85     927.28  5392620032\n3      927.45       906.65      927.45     902.37  4704940032\n4      905.73       909.73      910.00     896.81  4991549952",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Open Price</th>\n      <th>Close Price</th>\n      <th>High Price</th>\n      <th>Low Price</th>\n      <th>Volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>902.99</td>\n      <td>931.80</td>\n      <td>934.73</td>\n      <td>899.35</td>\n      <td>4048270080</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>929.17</td>\n      <td>927.45</td>\n      <td>936.63</td>\n      <td>919.53</td>\n      <td>5413910016</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>931.17</td>\n      <td>934.70</td>\n      <td>943.85</td>\n      <td>927.28</td>\n      <td>5392620032</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>927.45</td>\n      <td>906.65</td>\n      <td>927.45</td>\n      <td>902.37</td>\n      <td>4704940032</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>905.73</td>\n      <td>909.73</td>\n      <td>910.00</td>\n      <td>896.81</td>\n      <td>4991549952</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "train_dataset = \"train.csv\"\n",
    "train = pd.read_csv(train_dataset)\n",
    "\n",
    "# Since Date is not related to the price, so I just drop it\n",
    "train = train.drop([\"Date\"], axis=1)\n",
    "\n",
    "train.info() # show info about training dataset, there are 2262 data\n",
    "train.head() # show first 5 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 252 entries, 0 to 251\nData columns (total 5 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   Open Price   252 non-null    float64\n 1   Close Price  252 non-null    float64\n 2   High Price   252 non-null    float64\n 3   Low Price    252 non-null    float64\n 4   Volume       252 non-null    int64  \ndtypes: float64(4), int64(1)\nmemory usage: 10.0 KB\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Open Price  Close Price  High Price  Low Price      Volume\n0     2683.73      2695.81     2695.89    2682.36  1846463232\n1     2697.85      2713.06     2714.37    2697.77  2090595328\n2     2719.31      2723.99     2729.29    2719.07  2100767744\n3     2731.33      2743.15     2743.45    2727.92  1918869120\n4     2742.67      2747.71     2748.51    2737.60  1894823936",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Open Price</th>\n      <th>Close Price</th>\n      <th>High Price</th>\n      <th>Low Price</th>\n      <th>Volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2683.73</td>\n      <td>2695.81</td>\n      <td>2695.89</td>\n      <td>2682.36</td>\n      <td>1846463232</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2697.85</td>\n      <td>2713.06</td>\n      <td>2714.37</td>\n      <td>2697.77</td>\n      <td>2090595328</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2719.31</td>\n      <td>2723.99</td>\n      <td>2729.29</td>\n      <td>2719.07</td>\n      <td>2100767744</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2731.33</td>\n      <td>2743.15</td>\n      <td>2743.45</td>\n      <td>2727.92</td>\n      <td>1918869120</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2742.67</td>\n      <td>2747.71</td>\n      <td>2748.51</td>\n      <td>2737.60</td>\n      <td>1894823936</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "test_dataset = \"test.csv\"\n",
    "test = pd.read_csv(test_dataset)\n",
    "\n",
    "test = test.drop([\"Date\"], axis=1)\n",
    "test.info() # there are 252 data for testing\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we want to predict whether it's go up or down, not precise price\n",
    "# Open, High, Low price and volume are features to train, Close price is used for determine up or down\n",
    "# Note: close prices are not always the same as open price in the next day\n",
    "def data_split(dataset):\n",
    "    o = dataset['Open Price']\n",
    "    c = dataset['Close Price']\n",
    "\n",
    "    x = dataset.loc[:, dataset.columns != 'Close Price']\n",
    "    y = [] # 1 for higher, 0 for lower or equal\n",
    "    for i in range(len(c)):\n",
    "        if(c[i] > o[i]):\n",
    "            y.append(1)\n",
    "        else:\n",
    "            y.append(0)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation function for training results\n",
    "def evaluate(model, x_train, y_train, x_test, y_test):\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    train_predict = model.predict(x_train)\n",
    "    test_predict = model.predict(x_test)\n",
    "\n",
    "    train_acc = metrics.accuracy_score(y_train, train_predict)\n",
    "    test_acc = metrics.accuracy_score(y_test, test_predict)\n",
    "\n",
    "    return train_acc, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "1. Volume might be too huge to prices, the result are clearly better after dropping\n",
    "\n",
    "Q: What about dividing volume?\n",
    "\n",
    "A: It seems better, that means unbalanced value would effect LR a lot\n",
    "\n",
    "2. What about Linear Regression?\n",
    "\n",
    "A: Not good, linear regression is trying to find a point on the line to fit, and stock model is not really suitable for it.\n",
    "\n",
    "Stock shouldn't use linear regression module to predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "----Without Any Processing----\nTraining accuracy: 0.5455349248452697\nTesting accuracy: 0.503968253968254\n----After Dropping Volume----\nTraining accuracy: 0.847922192749779\nTesting accuracy: 0.8214285714285714\n----After Dividing Volume----\nTraining accuracy: 0.8488063660477454\nTesting accuracy: 0.8293650793650794\n----Implement SGDClassifier----\nTraining accuracy: 0.4557913351016799\nTesting accuracy: 0.49603174603174605\n"
    }
   ],
   "source": [
    "x_train, y_train = data_split(train)\n",
    "x_test, y_test = data_split(test)\n",
    "clf = linear_model.LogisticRegression(multi_class=\"auto\", solver=\"lbfgs\", max_iter=100, penalty='l2')\n",
    "train_acc, test_acc = evaluate(clf, x_train, y_train, x_test, y_test)\n",
    "\n",
    "print('----Without Any Processing----')\n",
    "print('Training accuracy: ' + str(train_acc))\n",
    "print('Testing accuracy: ' + str(test_acc))\n",
    "\n",
    "x_train_nv = x_train.drop(['Volume'], axis=1)\n",
    "x_test_nv = x_test.drop(['Volume'], axis=1)\n",
    "train_acc, test_acc = evaluate(clf, x_train_nv, y_train, x_test_nv, y_test)\n",
    "\n",
    "print('----After Dropping Volume----')\n",
    "print('Training accuracy: ' + str(train_acc))\n",
    "print('Testing accuracy: ' + str(test_acc))\n",
    "\n",
    "x_train_dv = x_train\n",
    "for i in range(len(x_train_dv)):\n",
    "    x_train_dv['Volume'][i] = x_train_dv['Volume'][i] / 1000000\n",
    "\n",
    "x_test_dv = x_test\n",
    "for i in range(len(x_test_dv)):\n",
    "    x_test_dv['Volume'][i] = x_test_dv['Volume'][i] / 1000000\n",
    "\n",
    "train_acc, test_acc = evaluate(clf, x_train_dv, y_train, x_test_dv, y_test)\n",
    "print('----After Dividing Volume----')\n",
    "print('Training accuracy: ' + str(train_acc))\n",
    "print('Testing accuracy: ' + str(test_acc))\n",
    "\n",
    "clf2 = linear_model.SGDClassifier(loss=\"perceptron\", eta0=1, learning_rate=\"constant\", penalty=None)\n",
    "train_acc, test_acc = evaluate(clf2, x_train_nv, y_train, x_test_nv, y_test)\n",
    "print('----Implement SGDClassifier----')\n",
    "print('Training accuracy: ' + str(train_acc))\n",
    "print('Testing accuracy: ' + str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "\n",
    "1. the value of volume seems not affect accuracy, cause NN is used to extract features from their values. the amount isn't matter\n",
    "\n",
    "2. the result without volume seems better, however it's still bad\n",
    "\n",
    "3. The features we put into NN should be normalized, or it's scale will affect it's training result\n",
    "\n",
    "But the features without volume somehow made the result worsen\n",
    "\n",
    "```\n",
    "----After Normalized----\n",
    "Training accuracy: 0.6710875331564987\n",
    "Testing accuracy: 0.623015873015873\n",
    "```\n",
    "\n",
    "Maybe dropping volume would make the features too few to make a classifier\n",
    "\n",
    "4. Enlarging hidden layers won't get a better result. However, hidden layers with small sizes ((2,0) for example) might be unuseful with terrible acc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "----Without Any Processing----\nTraining accuracy: 0.45446507515473034\nTesting accuracy: 0.49603174603174605\n----After Dropping Volume----\nTraining accuracy: 0.5455349248452697\nTesting accuracy: 0.503968253968254\n----After Normalized----\nTraining accuracy: 0.8483642793987621\nTesting accuracy: 0.8293650793650794\n"
    }
   ],
   "source": [
    "x_train, y_train = data_split(train)\n",
    "x_test, y_test = data_split(test)\n",
    "x_train_nv = x_train.drop(['Volume'], axis=1)\n",
    "x_test_nv = x_test.drop(['Volume'], axis=1)\n",
    "clf = neural_network.MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5,), random_state=1)\n",
    "\n",
    "train_acc, test_acc = evaluate(clf, x_train, y_train, x_test, y_test)\n",
    "\n",
    "print('----Without Any Processing----')\n",
    "print('Training accuracy: ' + str(train_acc))\n",
    "print('Testing accuracy: ' + str(test_acc))\n",
    "\n",
    "train_acc, test_acc = evaluate(clf, x_train_nv, y_train, x_test_nv, y_test)\n",
    "\n",
    "print('----After Dropping Volume----')\n",
    "print('Training accuracy: ' + str(train_acc))\n",
    "print('Testing accuracy: ' + str(test_acc))\n",
    "\n",
    "# Multi-layer Perceptron is sensitive to feature scaling. Normalizing should get better result\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_nm = scaler.transform(x_train)\n",
    "x_test_nm = scaler.transform(x_test)\n",
    "\n",
    "train_acc, test_acc = evaluate(clf, x_train_nm, y_train, x_test_nm, y_test)\n",
    "\n",
    "print('----After Normalized----')\n",
    "print('Training accuracy: ' + str(train_acc))\n",
    "print('Testing accuracy: ' + str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying another way for preprocessing and see if it will get better\n",
    "\n",
    "To calculate the difference between open price and high/low price\n",
    "\n",
    "It might reflect better feature for training, and it turns out better\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "The way to treat data is a huge topic to ML or NN module, the same data but represent in a different way would affect the training result.\n",
    "\n",
    "That is, preprocessing is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "----Using Another Logic----\nTraining accuracy: 0.852343059239611\nTesting accuracy: 0.8293650793650794\n"
    }
   ],
   "source": [
    "train_difference_low = []\n",
    "train_difference_high = []\n",
    "for i in range(len(x_train)):\n",
    "    train_difference_low.append(x_train['Open Price'][i] - x_train['Low Price'][i])\n",
    "    train_difference_high.append(x_train['Open Price'][i] - x_train['High Price'][i])\n",
    "\n",
    "difference_dict = {\n",
    "    \"difference_low\" : train_difference_low,\n",
    "    \"difference_high\" : train_difference_high\n",
    "}\n",
    "\n",
    "x_train_df = pd.DataFrame(difference_dict)\n",
    "\n",
    "test_difference_low = []\n",
    "test_difference_high = []\n",
    "for i in range(len(x_test)):\n",
    "    test_difference_low.append(x_test['Open Price'][i] - x_test['Low Price'][i])\n",
    "    test_difference_high.append(x_test['Open Price'][i] - x_test['High Price'][i])\n",
    "\n",
    "difference_dict = {\n",
    "    \"difference_low\" : test_difference_low,\n",
    "    \"difference_high\" : test_difference_high\n",
    "}\n",
    "\n",
    "x_test_df = pd.DataFrame(difference_dict)\n",
    "\n",
    "clf = neural_network.MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5,), random_state=1)\n",
    "\n",
    "train_acc, test_acc = evaluate(clf, x_train_df, y_train, x_test_df, y_test)\n",
    "\n",
    "print('----Using Another Logic----')\n",
    "print('Training accuracy: ' + str(train_acc))\n",
    "print('Testing accuracy: ' + str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other implementation: SVC\n",
    "\n",
    "SVC would find a optimal hyperplane to divide between data\n",
    "\n",
    "In this case, it might be suitable because the goal is simple: to determined whether it's go higher or lower\n",
    "\n",
    "And the features are also simple to read\n",
    "\n",
    "Results: Training acc is good for the first sight, but testing shows that it's severely overfitted\n",
    "\n",
    "The RBF kernel are fast and easy to train, but it will be overfitting in this case\n",
    "\n",
    "Changed to linear kernel below, and it takes much time. But the result seems to be much more reasonable compare to other methods\n",
    "\n",
    "And the result is alike to Logistic regression\n",
    "\n",
    "Yet, linear classification might reflect to actual situation to stock price as well, you can't find a certain pattern for it with just opening and high/low price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "----Without Any Processing----\nTraining accuracy: 0.9973474801061007\nTesting accuracy: 0.503968253968254\n"
    }
   ],
   "source": [
    "x_train, y_train = data_split(train)\n",
    "x_test, y_test = data_split(test)\n",
    "\n",
    "x_train_dv = x_train\n",
    "for i in range(len(x_train_dv)):\n",
    "    x_train_dv['Volume'][i] = x_train_dv['Volume'][i] / 1000000\n",
    "\n",
    "x_test_dv = x_test\n",
    "for i in range(len(x_test_dv)):\n",
    "    x_test_dv['Volume'][i] = x_test_dv['Volume'][i] / 1000000\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train_dv)\n",
    "x_train_nm = scaler.transform(x_train_dv)\n",
    "x_test_nm = scaler.transform(x_test_dv)\n",
    "\n",
    "clf = svm.SVC(gamma='auto')\n",
    "\n",
    "train_acc, test_acc = evaluate(clf, x_train_nv, y_train, x_test_nv, y_test)\n",
    "\n",
    "print('----Without Any Processing----')\n",
    "print('Training accuracy: ' + str(train_acc))\n",
    "print('Testing accuracy: ' + str(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "----Change Another Kernel----\nTraining accuracy: 0.8465959328028294\nTesting accuracy: 0.8293650793650794\n"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear', probability=True, gamma='auto') # using ploy kernel might take too much time to find classification\n",
    "\n",
    "train_acc, test_acc = evaluate(clf, x_train_nv, y_train, x_test_nv, y_test)\n",
    "\n",
    "print('----Change Another Kernel----')\n",
    "print('Training accuracy: ' + str(train_acc))\n",
    "print('Testing accuracy: ' + str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "1. The way we treat the data is important, the same module with different interpretation with data would lead to different result\n",
    "\n",
    "2. Using only open/high/low price and volume is fair enough to predict whether close price will go higher or lower\n",
    "\n",
    "All three method can reach up to 80% acc easily with simple implementation, but it's a long way to achieve over 90% acc\n",
    "\n",
    "3. However, the actual situation of stock prices changing is heavily depending on incidents in real life, and the effect is rapid.\n",
    "\n",
    "S&P 500 is a capitalization-weighted index for major 500 companies in America, and would show the overall economy situation\n",
    "\n",
    "There are four major drops in the history of S&P 500:\n",
    "\n",
    "- The dot-com bubble in 2000\n",
    "\n",
    "- The financial crisis of 2007–08\n",
    "\n",
    "- China–United States trade war started in 2018\n",
    "\n",
    "- COVID-19 epidemic in 2020\n",
    "\n",
    "Maybe using a crawler for getting breaking news \n",
    "\n",
    "And analysis the content is positive or negative to economy might achieve better prediction with more than 83% accuracy\n",
    "\n",
    "## References\n",
    "\n",
    "- https://en.wikipedia.org/wiki/S%26P_500_Index\n",
    "\n",
    "- stock price chart in google search\n",
    "\n",
    "- https://stats.stackexchange.com/questions/43538/what-is-the-difference-between-logistic-regression-and-neural-networks\n",
    "\n",
    "- https://medium.com/jameslearningnote/%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E7%AC%AC3-4%E8%AC%9B-%E6%94%AF%E6%8F%B4%E5%90%91%E9%87%8F%E6%A9%9F-support-vector-machine-%E4%BB%8B%E7%B4%B9-9c6c6925856b\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/neural_networks_supervised.html"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitbaseconda6d58fb85517a4fdc9e3e495e8d3e720e",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}